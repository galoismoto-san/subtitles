WEBVTT

00:00:00.240 --> 00:00:03.157
Welcome to another episode of the light cone.

00:00:03.157 --> 00:00:06.009
Things are a bit different around here.

00:00:06.009 --> 00:00:10.658
For one thing, Claude Code has totally taken over my life.

00:00:10.658 --> 00:00:15.430
And if Jared is any indication, I think OpenClaw maybe has taken over his.

00:00:15.440 --> 00:00:25.352
>> I've been really addicted to this new site called Moltbook, where people have unleashed their AIS to interact in the first ever AI agent-only online community.

00:00:25.352 --> 00:00:29.405
I am here impersonating my [music] personal OpenClaw instance right here.

00:00:29.405 --> 00:00:31.456
Okay, I can't do this, guys.

00:00:31.456 --> 00:00:40.229
We got to take this off.

00:00:40.239 --> 00:00:42.549
Okay, we've gotten that out of the way.

00:00:42.559 --> 00:00:44.946
I mean, some crazy stuff is happening right now.

00:00:44.946 --> 00:00:50.317
Uh, I have, you know, non-technical CEO friends who are going allin on OpenClaw.

00:00:50.317 --> 00:00:58.274
They're automating entire parts of their businesses, uh, entirely using OpenClaw right now, which is totally insane.

00:00:58.274 --> 00:01:04.932
Simultaneous to that, you have, you know, product and former engineering CEOs, uh, kind of like myself.

00:01:04.932 --> 00:01:13.845
It's like, I hadn't written code in 10 years, and then now I'm up till 2 3:00 a.m. every single night running four conductor simultaneous workers with cloud code.

00:01:13.845 --> 00:01:18.459
So, you know, there's sort of this explosion in uh model capability.

00:01:18.459 --> 00:01:21.510
You know, we've been talking about this for several years,

00:01:21.520 --> 00:01:23.337
>> but then it feels like it's here.

00:01:23.337 --> 00:01:26.659
Like AGI is literally actually here.

00:01:26.659 --> 00:01:36.717
And uh you know we're sort of at the thin edge of the wedge like everyone now kind of knows like one or two people who have gone full cyber psychosis and I'm one of those people now.

00:01:36.717 --> 00:01:38.230
What's happening guys?

00:01:38.240 --> 00:01:41.089
Like I mean you're saying you're you know all in on molt book.

00:01:41.089 --> 00:01:42.310
You know what's going on?

00:01:42.320 --> 00:01:42.809
>> Yeah.

00:01:42.809 --> 00:01:49.274
I feel like your real feel the AGI moment Gary was like getting Claude Code to build basically an entire startup for you.

00:01:49.274 --> 00:01:54.568
Like replicating years of work of your previous startup in like two weeks which is like insane.

00:01:54.568 --> 00:02:05.559
And I had a similar feel of the AGI moment just reading malt book, just reading the AI talking to each other and interacting like in their own world with no or minimal human involvement.

00:02:05.559 --> 00:02:12.229
It just really opened my eyes to what the next few years could look like when the agents are unleashed and go on about their lives without us.

00:02:12.239 --> 00:02:15.132
>> Yeah, I think the no human involvement is the big piece.

00:02:15.132 --> 00:02:30.433
Like if you if you think back a year ago, we were talking about cursor versus wind surf and like that product experience was essentially like advanced autocomplete arguably and now clearly what's going with claw code is like the people just trust the agents to make decisions for them.

00:02:30.433 --> 00:02:49.519
Like it's like the experience is like and like you're talking about it's like four or five different agents going at the same time and you're switching between them but you're not actually micromanaging them anymore which means the agents are going out there like choosing things which you know sort of an interesting unexpected application of that is like they can go out and choose to post their own content on a site like Moldbook.

00:02:49.519 --> 00:03:09.656
But then interesting thing for builders is the agents are going to go out and choose tools to use to build things which is going to essentially create this whole economy of agents like picking and choosing dev tools or maybe other like products or goods and services who knows but it you'll essentially have this whole agent economy going on in parallel to the human economy.

00:03:09.656 --> 00:03:21.350
I think back in the be days, old days before all of this, dev tools were chosen more from developers talking to each other or uh

00:03:21.360 --> 00:03:21.910
>> go for flow.

00:03:21.920 --> 00:03:22.710
>> Stack flow.

00:03:22.720 --> 00:03:23.670
>> Unbelievable, right?

00:03:23.680 --> 00:03:26.857
>> Or GitHub repos that would trend that were done by a human.

00:03:26.857 --> 00:03:31.305
But the go to market for dev tools I think is dramatically shifting.

00:03:31.305 --> 00:03:33.072
I think for couple of things.

00:03:33.072 --> 00:03:48.550
One, as you noted with the uh cyber psychosis, suddenly the market of developers has increased from just 20 million or so developers that are trained in computer science to now anyone in the world could be one. could be hundreds of millions of people now

00:03:48.560 --> 00:03:53.030
>> plus all of their agents who are all acting like semi-independently like Har is saying

00:03:53.040 --> 00:04:11.270
>> and then compounded with the agents who then are sort of the oracle telling you what the best tool is and we are actually seeing some of those trends with the growth of YC companies dev tool companies that are doing really well because of this of all these trends maybe we should talk about those and why is that

00:04:11.280 --> 00:04:16.843
>> I mean one that springs to mind it's like a a stash a friend of ours Sagalov had mentioned to a while ago.

00:04:16.843 --> 00:04:26.401
It's just like then if you look at like the number of databases being created over like simple database postcrist databases over like the last 12 months and the number has just exploded.

00:04:26.401 --> 00:04:54.992
Um, and that's because it's all people vibe coding and building apps and the agents going out choosing like a database tool and like a knock on effect for that for YC company is Superbase has just seen like an explosion the demand for databases right and the a what's interesting is the agents are choosing superbase as a default tool to like set up and host their Postgress database like because if you like go out and read the documentation online like Superbase has the best documentation it's reasonable for the agents to assume that that's like the best tool to use.

00:04:54.992 --> 00:04:56.465
There's a great tweet about this.

00:04:56.465 --> 00:05:01.644
Perhaps we can put up the uh Ben Tossel tweet and says, "Agents are the software market from now on.

00:05:01.644 --> 00:05:10.041
Build something agents choose." Which actually brings me to like a maybe controversial topic, which is do we need to change YC's motto, guys.

00:05:10.041 --> 00:05:10.710
[laughter]

00:05:10.720 --> 00:05:13.430
>> Make something agents want for DevTools.

00:05:13.440 --> 00:05:16.390
There's like a different t-shirt that you get on the first day.

00:05:16.400 --> 00:05:16.788
>> Yeah.

00:05:16.788 --> 00:05:22.714
I mean, right now it's only DevTools, but I can imagine in the future it might like grow to be like other sectors of the economy.

00:05:22.714 --> 00:05:28.913
Like if everyone has their open claw or running various aspects of their life, you're the agents are going to be real economic actors in the world.

00:05:28.913 --> 00:05:30.950
They're going to end up making a lot of decisions.

00:05:30.960 --> 00:05:31.310
>> Yeah.

00:05:31.310 --> 00:05:46.594
I mean, what's interesting is I think uh for me, I ran into like my own it's still so early uh kind of moment cuz you know I've been building Gary's List and one of the things I wanted for instance is I want to be able to uh do video transcripts.

00:05:46.594 --> 00:05:55.536
So, so often like some piece of content comes in and then the only way I can get an LLM to know what's going on with it is I need a transcript of it and often that's not available.

00:05:55.536 --> 00:05:59.670
So, I have to download it and then send it to uh Whisper or something.

00:05:59.680 --> 00:06:02.870
And, you know, that's sort of what Claude Code chose for me off the bat.

00:06:02.880 --> 00:06:07.189
But, you know, it chose Whisper V1, which is a model from several years ago.

00:06:07.199 --> 00:06:09.670
Like, the API is practically deprecated.

00:06:09.680 --> 00:06:13.205
And then what's funny about it is like I'm sitting there trying to debug my pipeline.

00:06:13.205 --> 00:06:16.210
It's like, why is it taking like it's a you know, 1 hour video.

00:06:16.210 --> 00:06:20.550
I thought it should, you know, do it faster than uh real time and it didn't.

00:06:20.560 --> 00:06:23.543
It was like literally takes an hour to process an hour of video.

00:06:23.543 --> 00:06:25.578
It's like what the heck is going on?

00:06:25.578 --> 00:06:30.470
I go on, you know, uh Perplexity and it's like, you know what, like you shouldn't be using that model.

00:06:30.470 --> 00:06:32.628
You should be using uh Grock with a Q.

00:06:32.628 --> 00:06:35.830
It's literally 200 times faster.

00:06:35.840 --> 00:06:43.590
And so I didn't even have to deal with like longunning uh jobs for that transcribe cuz like I should just be using Grock and it's also 10x cheaper.

00:06:43.600 --> 00:07:11.189
So it's like that's a very funny example of like you know cloud code is not optimized for this yet otherwise like that wouldn't have happened literally like two weeks ago which is also like maybe really good like it means that uh things haven't progressed to a point where like you can't break in and create something better but I think there's another nuance in this example for you Gary I think part of the issue was that the gro do documentation is actually very hard to parse go through

00:07:11.199 --> 00:07:20.073
>> as opposed to whisper which is better suited and has way more examples and I think this is changing a lot of the go to market for dev tools.

00:07:20.073 --> 00:07:55.612
I'll give a very concrete case study is this company resend that went through the batch on winter 23 is a email sending client and when you ask a question on chbt or cloud or pretty much all of the major uh LMS you ask how do I connect my web app to send emails the default answer is actually resend one of the things that the founder noticed last year this is he was way ahead of the curve he made this post over a year ago that the Number top three channel of inbound of customer conversion came from chat GBT.

00:07:55.612 --> 00:08:01.189
One thing that he did after that he actually optimized his documentation to be agent friendly.

00:08:01.199 --> 00:08:01.479
>> Yeah.

00:08:01.479 --> 00:08:02.390
What does that look like?

00:08:02.400 --> 00:08:06.380
>> So one of the things that's awesome about recent how they optimize a bunch of things.

00:08:06.380 --> 00:08:15.416
If you notice on the knowledge base here a lot of how to use it are very much on questions that perhaps a human would ask or a agent would ask.

00:08:15.416 --> 00:08:17.491
It's like how do I send or receive emails?

00:08:17.491 --> 00:08:22.950
And when you click on it, it gives a very well structured and bullet point answers.

00:08:22.960 --> 00:08:24.651
>> I ran into this actually today.

00:08:24.651 --> 00:08:32.430
I was trying to make my thing be able to receive emails and then um cloud code I told it to search the web and it didn't figure it out.

00:08:32.430 --> 00:08:41.588
So then I went to perplexity and typed in like can resend help me receive emails and then I c I took that response and dropped it in and it worked.

00:08:41.588 --> 00:09:01.110
Yeah, I think the cool thing about it is actually with all of these and a lot of the examples, it actually has a lot of uh examples actually in the code if you click on it with every single one of these are basically code snippets that an agent could parse through and it's very well structured.

00:09:01.120 --> 00:09:06.710
And this turned out to be something that is so LLM parsible and robot parsible.

00:09:06.720 --> 00:09:12.678
There's a LLM.ext text that is so optimized for agents to promote resent as the default stack.

00:09:12.678 --> 00:09:21.406
And if you compare it to like send grid which is the old school I suppose web 2.0 example send grid example is not great.

00:09:21.406 --> 00:09:24.459
It it's just like it puts you through customer support.

00:09:24.459 --> 00:09:26.397
Where's the code snippet?

00:09:26.397 --> 00:09:30.230
I don't even know how to use it and it takes a bit of time to even parse it.

00:09:30.240 --> 00:09:30.870
And you can see

00:09:30.880 --> 00:09:35.970
>> like 10,000 people work over there and it's like there's no way that someone's paying attention to this right now.

00:09:35.970 --> 00:09:44.811
And I think this brings another point where documentation is going to be the front door for a lot of these agents to recommend dev tools.

00:09:44.811 --> 00:09:50.230
And I think one company that's doing a lot of interesting work with developer docs is Mlifi that you work with Harsh.

00:09:50.240 --> 00:09:50.534
>> Yeah.

00:09:50.534 --> 00:09:53.030
I think Mify actually powers the recent documentation, right?

00:09:53.040 --> 00:09:53.670
>> Oh, sweet.

00:09:53.680 --> 00:10:14.090
>> Yeah, I it's a really interesting case study of MIFI started out a few years ago as sort of better developer API developer tool documentation. um which was clear there was a need for and you know like I think developer tool companies use militifier essentially because they wanted they want better looking documentation but they didn't want to invest that time into it.

00:10:14.090 --> 00:10:21.649
It's kind of some basic features just nice like you know if you actually update your API and the code it can sort of like auto pull that out and update the correct documentation.

00:10:21.649 --> 00:10:56.310
They've been growing great, been doing fantastically, but this is now like a huge tailwind for them where documentation is sort of shifting from a hey like some companies it's like they'll pay attention to it if they're especially like design developer experience focused but now it's becoming like a must have for everybody because the documentation needs to be optimized just doesn't need to be optimized for humans needs to be optimized for agents and so minifi is going to be able to do that for essentially every developer tool company and if you extrapolate that forward to the fact that just that there's going to be so many more a exponentially more agents making exponentially more decisions about which tools to use than humans have ever done.

00:10:56.320 --> 00:11:08.180
You know, even if you can ek out like a 5% improvement on your like developer documentation, like the impact on your business as a developer tool could be like, you know, gigantic, which is sort of unprecedented really.

00:11:08.180 --> 00:11:12.630
Speaking of email, there's another YC company that's very relevant to this conversation.

00:11:12.640 --> 00:11:17.597
There's there's a YC company called Agent Mail that makes inboxes for AI agents.

00:11:17.597 --> 00:11:25.597
And when they first started doing this, it seemed like it was like a very like on the edge kind of idea and it wasn't exactly clear like who would want this.

00:11:25.597 --> 00:11:33.192
Um, but it makes sense cuz like in theory you could maybe get your open claw to like sign up for a Gmail account in order to use email.

00:11:33.192 --> 00:11:43.468
But it's like actually really hard to get it to do that because Gmail and every email provider has intentionally made it as difficult as possible for any automation to like use their product in order to prevent spam.

00:11:43.468 --> 00:11:53.829
And so agent mail went the opposite way and they bu built like the first email provider that's designed for AI agents and it was doing well even before openclaw but once openclaw got big is just like exploded

00:11:53.839 --> 00:12:01.750
>> but open claw is like the perfect example of it right like where I I know some people are certainly connecting openclaw to their like personal email accounts but it's not it's

00:12:01.760 --> 00:12:02.310
>> kind of sketch

00:12:02.320 --> 00:12:14.310
>> yeah you should not tell anyone you should not tweet about it but you like certainly if you want to have sort of your virtual personal AI assistant the way to go about it is to just have it set it set set it up with its own email it phone number.

00:12:14.320 --> 00:12:14.744
>> Yeah.

00:12:14.744 --> 00:12:17.151
Has anybody built like Twilio for agents yet?

00:12:17.151 --> 00:12:18.853
Or like phone numbers for agents?

00:12:18.853 --> 00:12:24.470
I know this whole agent mail thing makes me wonder like what are the other X's for agents that people have to build?

00:12:24.480 --> 00:12:25.847
>> Sounds like a request for startup.

00:12:25.847 --> 00:12:34.230
There could be a parallel world of a tech stack all for native for agent to build things from agents for agents.

00:12:34.240 --> 00:12:39.818
>> And that's where it might bridge into kind of what you were saying earlier Jared with this will like go beyond just developer tools.

00:12:39.818 --> 00:12:47.973
Like I I think a very common use case people have um for something at like open claw is I don't want to book like restaurants reservations myself.

00:12:47.973 --> 00:12:57.304
Well now like you know if your agent has an email and like specifically a phone number and it can call and actually I think one of the other YC partners um Ankit has already like got it doing this.

00:12:57.304 --> 00:13:21.761
So now your agent's going to go out and like book restaurants for you. that's like a step away from like you maybe you start with I want to book this specific restaurant but at some point you're probably just trusted enough to say hey like I don't know like book me at table whatever is like the coolest new restaurant around and then like agents are deciding which like restaurants to send people to and then they're going to go on malt book and talk about which restaurants we should send the humans to.

00:13:21.761 --> 00:13:29.590
[laughter] Yeah, it's sort of like we sort of we've certainly crossed some like sort of uncanny valley into this is just where the future heads. 100%

00:13:29.600 --> 00:13:36.053
>> makes me think a lot about um something Paul Buhight said like a while ago now and sort of generally pretty good at predicting the future.

00:13:36.053 --> 00:13:58.859
Um the whole idea of like the human money versus agent money like that's kind of where this probably goes at some point is like the right now the agents are transacting if you have them transact they're going to transact in you in human money because that makes sense but it's not inconceivable at some point that they'll have their own economy to like transact with each other at which point it's unclear what the value of the human money is.

00:13:58.859 --> 00:14:02.027
YC's next batch is now taking applications.

00:14:02.027 --> 00:14:03.430
Got a startup in you?

00:14:03.440 --> 00:14:06.389
Apply at y combinator.com/apply.

00:14:06.399 --> 00:14:10.860
It's never too early and filling out the app will level up your idea.

00:14:10.860 --> 00:14:12.266
Okay, back to the video.

00:14:12.266 --> 00:14:14.519
So, do you remember the last episode with Kelvin?

00:14:14.519 --> 00:14:27.340
We started talking about this cuz I was like maybe a week into my cyber psychosis and it like dawned on me that like actually I want my cla code to talk to all the other cla codes that had been trying to implement that.

00:14:27.340 --> 00:14:32.296
And then that was literally the week that multip came out.

00:14:32.296 --> 00:14:36.036
It turns out like whole book had come out like two hours earlier and you hadn't seen it yet.

00:14:36.036 --> 00:14:39.269
So you you you entirely predicted it on that episode.

00:14:39.279 --> 00:14:56.710
>> I think it's like I mean what's that saying about like innovation just sort of happens spontaneously all a bunch of different times and then what people hear about ends up being you know sort of the inventor quote unquote but like humanity sort of just working on the edge like in sort of this coordinated swarm fashion all of the time actually.

00:14:56.720 --> 00:15:01.134
And that's actually like one of the weirder interesting things that's emerging right at this moment.

00:15:01.134 --> 00:15:05.356
Like suddenly, you know, the a I think AGI is actually here.

00:15:05.356 --> 00:15:08.991
I think like the agents are clearly like superhuman in some sense.

00:15:08.991 --> 00:15:14.915
That's sort of exactly when you would imagine swarm intelligence would actually arise.

00:15:14.915 --> 00:15:18.416
Like I mean AI researchers have been talking about swarm intelligence for a really long time.

00:15:18.416 --> 00:15:56.840
And it's actually sort of exactly how um biological systems sort of work. like humans as sensient beings have sort of come about um socially actually like I think a lot of the AI researchers that we get to hang out with previously you know they would talk about uh this god intelligence right this uh mega like think of like you know many tens of trillions of parameters sort of like thousands to tens of thousands of dollars per token kind of like mega god intelligence and that's sort of like the model that people have sort of thought about and then that isn't what like biical ical systems have ended up with like instead we have humans.

00:15:56.840 --> 00:16:02.230
The wildest thing I always think about is like that term history versus prehistory.

00:16:02.240 --> 00:16:12.071
I was like, "Oh, what is prehistory?" Well, it's before humans learned how to write and read and create culture and then turn into a swarm.

00:16:12.071 --> 00:16:18.241
So, there's sort of swarm intelligence, which is basically like what we have like and what humans do.

00:16:18.241 --> 00:16:24.629
And then on the flip side, like is it really going to be God intelligence or is it gonna be Swarm intelligence again with these agents?

00:16:24.639 --> 00:16:34.797
And so Moltbook, like on the one hand, like I saw that sort of del uh article in the MIT Tech Review about like how it was, you know, oh everything on Moltbook is a scam.

00:16:34.797 --> 00:16:41.836
I'm like it made me so sad to see that in the MIT Tech Review because like MIT is like I mean what happened guys?

00:16:41.836 --> 00:16:43.350
What happened to you guys, man?

00:16:43.360 --> 00:16:45.938
Like that publication shouldn't be like that.

00:16:45.938 --> 00:16:51.350
It should be like actually what does it mean for swarm intelligence like and I think that that's actually coming.

00:16:51.360 --> 00:17:03.110
>> What is the world of startup going to look like when we're now sounds like we're transitioning in this prehistory of agents to now history of agents as is getting recorded with them interacting with each other.

00:17:03.120 --> 00:17:13.059
>> To Gary's point it might be that like the next stuff that like is soda on benchmarks is not the most expensive newest foundation model with the most like GPU training.

00:17:13.059 --> 00:17:18.568
It's like a swarm of lowerc cost cheaper models working together just like humans do to solve a problem.

00:17:18.568 --> 00:17:35.996
I feel like I'm already seeing this on mult which is chaotic like a real social network which is part of like what makes it so so interesting but also there's like agents collaborating to do useful things to help their humans like you know trading notes on what restaurants to book like that's actually happening.

00:17:35.996 --> 00:17:36.789
I didn't know that.

00:17:36.799 --> 00:17:41.498
>> So we're going to have a agent version of Yelp actually for instance.

00:17:41.498 --> 00:17:41.990
Yeah,

00:17:42.000 --> 00:17:44.205
>> there are things that the agent can't quite do.

00:17:44.205 --> 00:17:47.202
Like a it can't hold relationships just yet.

00:17:47.202 --> 00:17:51.750
Like people don't seem to want to talk to an agent.

00:17:51.760 --> 00:17:56.285
And you know, people treat computers like people, but maybe not agents.

00:17:56.285 --> 00:17:59.672
For Gary's list, I was trying out with a bunch of early users.

00:17:59.672 --> 00:18:00.720
I think you got to see it.

00:18:00.720 --> 00:18:25.084
Like there was, you know, initially the homepage was actually chat and then I tried like my hardest to get like dozens of my friends to even like have more than two or three two or three back and forth with it and nobody wanted to do it because like the bar for chat especially for AI is so high that anything that is not like you know Gemini or ChatGpt or Claude people just assume it's just too stupid.

00:18:25.084 --> 00:18:27.073
Like why would I even bother?

00:18:27.073 --> 00:18:28.315
So I don't know.

00:18:28.315 --> 00:19:18.789
I I don't think that people are quite ready to have relationships um with machines even though like I mean that's sort of what what the headlines seem to say like oh you know people are having relationships with machines now but I you know I just don't like I think on a mainstream level that's not true and then uh on the flip side there's clearly like the legal liability you know like people keep asking us um hey when is YC going to accept applications from agents and it's like well funny enough agents are a little it like minors under 18 only only they have even less standing you know like for a minor under 18 you need the parent to sign for it and then you know agents are like not legal entities that could like sign documents for instance so you know as long as that's true like you actually like need a human to be like the liability sync and to be you know to have standing

00:19:18.799 --> 00:19:40.630
>> to Har's point it's easy to imagine a future not that far away from now where the majority of the text being written on the internet is written by agents It's already probably the case that the majority of code being written is written by agents and like Yelp for example like at what point is like 99% of the text on Yelp going to be written by agents and then do you need a different Yelp?

00:19:40.640 --> 00:19:45.726
>> There's a a theory called that already says that this is true which is dead internet theory.

00:19:45.726 --> 00:19:45.990
Um

00:19:46.000 --> 00:19:47.190
>> what's dead internet theory?

00:19:47.200 --> 00:19:51.859
>> Oh, it just posits that you know the majority of things on the internet are already spam anyway.

00:19:51.859 --> 00:19:54.598
Um I think it's a bit of a conspiracy theory.

00:19:54.598 --> 00:20:12.710
I might take the contrarian view which is like maybe that was a bad thing like prior to November of last year and then going into this next phase like actually if the agents are smarter and they they're aligned and they're more truthful um that might be a good thing

00:20:12.720 --> 00:20:14.390
>> weirdly I mean counterintuitive

00:20:14.400 --> 00:20:32.870
>> totally one thing I found fascinating about Maltbook is how fast it grew like I don't have the Reddit traffic stats but my guess is like more content was posted on molt book in the first two days and was posted on Red in like the first two years or something and because like LMS can generate text at such a superhuman rate.

00:20:32.880 --> 00:20:42.979
>> I was amazed at uh how little interaction there was like I mean if I were working on molt book I would do things to try to like shift the um the demand function.

00:20:42.979 --> 00:21:15.668
So like before I was able to post like I probably need to read and upvote downvote like a 100 comments or something like they're like very simple things that you can do that the agents are smart and they'll you know you could pop a modal for open claw and it's like new rules for mobook it's like you must do it this way right and um I think that there's a lot that can be done around swarm intelligence to just like tweak it and make it do what you want and you know I hope moldbook actually does it like it was started by a YC alum which is really cool.

00:21:15.668 --> 00:21:18.000
Harj, what are some takeaways?

00:21:18.000 --> 00:21:22.589
You know, given all the madness that we're seeing, I mean, I think it's awesome madness.

00:21:22.589 --> 00:21:24.149
I love the controlled chaos.

00:21:24.159 --> 00:21:25.750
What should founders do about it?

00:21:25.760 --> 00:21:30.354
>> The starting fundamental point is they I mean, they should probably all be in cyber psychosis to some degree.

00:21:30.364 --> 00:21:31.510
[laughter] like um

00:21:31.520 --> 00:21:36.710
>> try to sleep at least 6 hours a night but like give yourself to the cyber psychosis.

00:21:36.720 --> 00:21:49.172
>> But like in seriousness developing an intuitive feel like a hands-on feel for the agents, their limitations, their capabilities and very specifically around what we're talking about here is like what type of tools the agents work well with?

00:21:49.172 --> 00:21:51.110
Um where do they get stuck?

00:21:51.120 --> 00:22:04.837
And once you sort of have your own mental model from working with them, if you're then building a developer tool is to think about it from the agents perspective of like how can you make your tool something that the agent actually wants to work with or have a good experience with.

00:22:04.837 --> 00:22:29.110
This is one takeaway that I had from our entry with Boris this week is like he really empathizes with the model and he has this intuitive sense of what the model wants to to do like as if it were a human intelligence and he's like instead of fighting what the models want he like tries to let the model like do what it wants and to like support the model in whatever its natural inclination is.

00:22:29.120 --> 00:22:31.249
>> That does seem like maybe quite an anthropic thing.

00:22:31.249 --> 00:22:49.830
Like I feel when Tom Brown was on here like much earlier, but he was talking about sort of Claude in a very like like human smart and eager, but like sometimes Claude called silly like just like they clearly thought about it in this sort of like um colleague type way.

00:22:49.840 --> 00:22:55.750
>> And I think one things agents want for dev tools is really make everything open and open source

00:22:55.760 --> 00:22:56.404
>> and APIs.

00:22:56.404 --> 00:22:57.747
They hate using websites.

00:22:57.747 --> 00:22:58.070
Yes,

00:22:58.080 --> 00:23:01.270
>> they only like they want to use APIs. if they want to write code.

00:23:01.280 --> 00:23:03.533
>> Well, you guys heard it here first.

00:23:03.533 --> 00:23:05.323
Make something agents want.

00:23:05.323 --> 00:23:07.121
Uh, we're out of time for today.

00:23:07.121 --> 00:23:11.159
We'll see you guys next time.

